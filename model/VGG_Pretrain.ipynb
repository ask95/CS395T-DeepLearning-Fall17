{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Lambda\n",
    "from keras import initializers\n",
    "from keras.utils import get_file\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "path = '/work/04381/ymarathe/maverick/yearbook/keras_yearbook/'\n",
    "data_path = '/work/04381/ymarathe/maverick/yearbook/'\n",
    "\n",
    "f = open(data_path + 'yearbook_train.txt', 'r')\n",
    "\n",
    "freq = {};\n",
    "normal_const = 0;\n",
    "\n",
    "for line in f:\n",
    "    line = line.rstrip()\n",
    "    image, year = line.split(\"\\t\")\n",
    "    if year in freq:\n",
    "        freq[year] += 1\n",
    "    else:\n",
    "        freq[year] = 1\n",
    "\n",
    "normal_const = np.sum(freq.values())\n",
    "for key in freq:\n",
    "    freq[key] = freq[key]/float(normal_const);\n",
    "    \n",
    "sorted_freq = collections.OrderedDict(sorted(freq.items()))\n",
    "\n",
    "idx = 0;\n",
    "class_weights_train = {}\n",
    "idx2year = {}\n",
    "\n",
    "for key in sorted_freq:\n",
    "    class_weights_train[idx] = sorted_freq[key]\n",
    "    idx2year[idx] = key\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batches(path, gen = ImageDataGenerator(), shuffle=True, class_mode=\"categorical\", batch_size=32, \n",
    "                target_size=(171, 186)):\n",
    "    return gen.flow_from_directory(path, shuffle=shuffle, batch_size=batch_size, target_size=target_size, \n",
    "                                   class_mode=class_mode)\n",
    "\n",
    "def gen_batches_flow(path, gen = ImageDataGenerator(), shuffle=True, batch_size=32):\n",
    "    return gen.flow(path, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#female_train = gen_batches(path + 'train/F')\n",
    "#male_train = gen_batches(path + 'train/M')\n",
    "#female_valid = gen_batches(path + 'valid/F')\n",
    "#male_valid = gen_batches(path + 'valid/M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = gen_batches(path + 'train')\n",
    "#valid = gen_batches(path + 'valid', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg19_conv_layers_sequential():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(171, 186, 3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    vgg_pretrain_weights = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    \"https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "                                    cache_subdir='models')\n",
    "    \n",
    "    model.load_weights(vgg_pretrain_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with tf.device('/gpu:0'):\n",
    "        #model.fit_generator(female_train, steps_per_epoch = female_train.samples/female_train.batch_size, epochs=1,\n",
    "                    #validation_data=female_valid, validation_steps = female_valid.samples/female_valid.batch_size)\n",
    "        #model.fit_generator(male_train, steps_per_epoch = male_train.samples/male_train.batch_size, epochs=1,\n",
    "                    #validation_data=male_valid, validation_steps = male_valid.samples/male_valid.batch_size)\n",
    "        #model.fit_generator(train, steps_per_epoch = train.samples/train.batch_size, epochs = 5, \n",
    "                            #validation_data = valid, \n",
    "                            #validation_steps = valid.samples/valid.batch_size)\n",
    "        #model.save_weights(path + 'weights_exp6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Experiment 1**\n",
    "- All layers trained\n",
    "- lr = 1e-4\n",
    "- Adam\n",
    "- Dense layers weight initialized \n",
    "- OVERFITTING is apparent\n",
    "- Epochs = 1\n",
    "\n",
    "Total params: 89,664,680\n",
    "\n",
    "Trainable params: 89,664,680\n",
    "\n",
    "Non-trainable params: 0\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 668s - loss: 5.1517 - acc: 0.0237 - val_loss: 4.7387 - val_acc: 0.0223\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 578s - loss: 4.1187 - acc: 0.0723 - val_loss: 4.4772 - val_acc: 0.0245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Experiment 2**\n",
    "- Motivation: loss function keeps decreasing in Experiment 1, maybe more epochs will increase accuracy?\n",
    "- Dense layers trained\n",
    "- lr = 1e-5\n",
    "- Dense layers weight initialized \n",
    "- alternatively improving values\n",
    "- Overfitting or not is not clear\n",
    "- Epochs = 5\n",
    "\n",
    "=================================================================\n",
    "\n",
    "Total params: 89,664,680\n",
    "\n",
    "Trainable params: 69,640,296\n",
    "\n",
    "Non-trainable params: 20,024,384\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 240s - loss: 13.6884 - acc: 0.0358 - val_loss: 11.4914 - val_acc: 0.0251\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 203s - loss: 11.5692 - acc: 0.0666 - val_loss: 9.2627 - val_acc: 0.0127\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 237s - loss: 8.4670 - acc: 0.1118 - val_loss: 6.3364 - val_acc: 0.0365\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 204s - loss: 6.4200 - acc: 0.1361 - val_loss: 5.8004 - val_acc: 0.0133\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 234s - loss: 5.2417 - acc: 0.1739 - val_loss: 5.1995 - val_acc: 0.0289\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 203s - loss: 4.6242 - acc: 0.1942 - val_loss: 5.1862 - val_acc: 0.0220\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 234s - loss: 4.0165 - acc: 0.2328 - val_loss: 4.8735 - val_acc: 0.0351\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 202s - loss: 3.7839 - acc: 0.2412 - val_loss: 5.0708 - val_acc: 0.0202\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 234s - loss: 3.4204 - acc: 0.2830 - val_loss: 4.7858 - val_acc: 0.0347\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 202s - loss: 3.2999 - acc: 0.2905 - val_loss: 5.0043 - val_acc: 0.0202\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 3**\n",
    "- Will batchnormalization help since theres is no improvement in validation accuracy\n",
    "- Weight initialized dense layers\n",
    "- Only dense layers trainable\n",
    "- Batchnormalized dense layers\n",
    "- Dropout = 0.5\n",
    "- lr = 1e-4\n",
    "- Overfits\n",
    "\n",
    "=================================================================\n",
    "\n",
    "Total params: 89,697,448\n",
    "\n",
    "Trainable params: 69,640,296\n",
    "\n",
    "Non-trainable params: 20,057,152\n",
    "\n",
    "_________________________________________________________________\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 242s - loss: 5.0252 - acc: 0.0388 - val_loss: 4.4513 - val_acc: 0.0190\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 205s - loss: 4.5141 - acc: 0.0941 - val_loss: 4.6469 - val_acc: 0.0136\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 4**\n",
    "- Motivation: Overfitting in Experiment 3, do more dropout\n",
    "- Weight initialized dense layers\n",
    "- Only dense layers trainable\n",
    "- Batchnormalization with dense layers\n",
    "- Dropout = 0.7\n",
    "- lr = 1e-4\n",
    "- Not much improvement\n",
    "\n",
    "Total params: 89,697,448\n",
    "\n",
    "Trainable params: 69,640,296\n",
    "\n",
    "Non-trainable params: 20,057,152\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 240s - loss: 5.4357 - acc: 0.0119 - val_loss: 4.5188 - val_acc: 0.0255\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 204s - loss: 5.2047 - acc: 0.0261 - val_loss: 4.5505 - val_acc: 0.0127\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 5**\n",
    "- Motivation: Loss keeps decreasing in Experiment 4, do more number of epochs\n",
    "- Weight initialized dense layers\n",
    "- Only dense layers trainable\n",
    "- Batchnormalization with dense layers\n",
    "- Dropout = 0.7\n",
    "- lr = 1e-4\n",
    "- Validation loss is not stable across epochs\n",
    "\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 240s - loss: 5.4000 - acc: 0.0125 - val_loss: 4.4933 - val_acc: 0.0381\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 205s - loss: 5.2335 - acc: 0.0199 - val_loss: 4.5120 - val_acc: 0.0213\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 239s - loss: 4.8773 - acc: 0.0416 - val_loss: 4.4056 - val_acc: 0.0206\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 205s - loss: 4.7485 - acc: 0.0563 - val_loss: 4.4966 - val_acc: 0.0138\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 236s - loss: 4.4608 - acc: 0.0814 - val_loss: 4.3931 - val_acc: 0.0184\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 204s - loss: 4.3454 - acc: 0.1029 - val_loss: 4.5639 - val_acc: 0.0119\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 236s - loss: 4.1044 - acc: 0.1265 - val_loss: 4.4471 - val_acc: 0.0217\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 204s - loss: 4.0820 - acc: 0.1358 - val_loss: 4.6092 - val_acc: 0.0133\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "379/379 [==============================] - 236s - loss: 3.8478 - acc: 0.1620 - val_loss: 4.4567 - val_acc: 0.0231\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "334/334 [==============================] - 204s - loss: 3.9038 - acc: 0.1616 - val_loss: 4.6779 - val_acc: 0.0119\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 6**\n",
    "- No separation of male and female data\n",
    "- lr = 1e-4\n",
    "- 3 epochs\n",
    "- BatchNorm with dense layers\n",
    "- Dense layers weight initialized\n",
    "- Only Dense layers trained\n",
    "- Training accuracy is very very high compared to accuracy on validation set\n",
    "- No improvement in validation set accuracy\n",
    "\n",
    "Total params: 89,697,448\n",
    "\n",
    "Trainable params: 69,640,296\n",
    "\n",
    "Non-trainable params: 20,057,152\n",
    "\n",
    "Epoch 1/5\n",
    "\n",
    "708/708 [==============================] - 443s - loss: 3.5136 - acc: 0.2312 - val_loss: 5.0918 - val_acc: 0.0282\n",
    "\n",
    "Epoch 2/5\n",
    "\n",
    "708/708 [==============================] - 441s - loss: 2.3899 - acc: 0.4080 - val_loss: 5.2752 - val_acc: 0.0249\n",
    "\n",
    "Epoch 3/5\n",
    "\n",
    "708/708 [==============================] - 437s - loss: 1.9634 - acc: 0.4918 - val_loss: 5.4608 - val_acc: 0.0282\n",
    "\n",
    "Epoch 4/5\n",
    "\n",
    "708/708 [==============================] - 436s - loss: 1.6964 - acc: 0.5481 - val_loss: 5.6526 - val_acc: 0.0278\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Experiment 7**\n",
    "- No separation of male and female data\n",
    "- Use only one dense layer\n",
    "- No dropout\n",
    "- Everything else stays same as Experiment 6\n",
    "- WOW! training accuracy is 96.9% after 3 epochs\n",
    "- WOW^2! training accuracy is 99.3% after 4 epochs\n",
    "- BUT... validation accuracy is abysmal! Validation loss keeps increasing!\n",
    "- QUESTION: WHY does the network NOT generalize well?\n",
    "- Is the training set so different from validation set?\n",
    "\n",
    "Epoch 1/4\n",
    " \n",
    "708/708 [==============================] - 426s - loss: 2.3755 - acc: 0.4281 - val_loss: 5.6640 - val_acc: 0.0308\n",
    "\n",
    "Epoch 2/4\n",
    "\n",
    "708/708 [==============================] - 426s - loss: 0.6264 - acc: 0.8555 - val_loss: 6.1181 - val_acc: 0.0268\n",
    "\n",
    "Epoch 3/4\n",
    "\n",
    "708/708 [==============================] - 422s - loss: 0.2287 - acc: 0.9644 - val_loss: 6.2639 - val_acc: 0.0211\n",
    "\n",
    "Epoch 4/4\n",
    "\n",
    "708/708 [==============================] - 422s - loss: 0.0844 - acc: 0.9935 - val_loss: 6.3802 - val_acc: 0.0231\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 8**\n",
    "- No separation of male and female data\n",
    "- Use only one dense layer\n",
    "- 50% dropout\n",
    "- Everything else stays same as Experiment 6\n",
    "- Even dropout doesn't help\n",
    "\n",
    "Total params: 72,899,752\n",
    "\n",
    "Trainable params: 52,858,984\n",
    "\n",
    "Non-trainable params: 20,040,768\n",
    "\n",
    "_________________________________________________________________\n",
    "Epoch 1/4\n",
    "708/708 [==============================] - 427s - loss: 2.8264 - acc: 0.3509 - val_loss: 5.4841 - val_acc: 0.0229\n",
    "\n",
    "Epoch 2/4\n",
    "\n",
    "708/708 [==============================] - 427s - loss: 1.1657 - acc: 0.6901 - val_loss: 5.6196 - val_acc: 0.0297\n",
    "\n",
    "Epoch 3/4\n",
    "\n",
    "708/708 [==============================] - 422s - loss: 0.6635 - acc: 0.8322 - val_loss: 5.8154 - val_acc: 0.0342\n",
    "\n",
    "Epoch 4/4\n",
    "\n",
    "708/708 [==============================] - 422s - loss: 0.3946 - acc: 0.9108 - val_loss: 6.2051 - val_acc: 0.0299\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 173, 188, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 171, 186, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 173, 188, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 171, 186, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 85, 93, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 87, 95, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 85, 93, 128)       73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 87, 95, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 85, 93, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 42, 46, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 44, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 42, 46, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 44, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 42, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 44, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 42, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 44, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 42, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 23, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 23, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 23, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 21, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 23, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 21, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 23, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 21, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              52432896  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 104)               426088    \n",
      "=================================================================\n",
      "Total params: 72,899,752\n",
      "Trainable params: 52,858,984\n",
      "Non-trainable params: 20,040,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = vgg19_conv_layers_sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, kernel_initializer='glorot_normal', bias_initializer=keras.initializers.Ones()))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(104, activation='softmax'))\n",
    "\n",
    "for layer in model.layers:\n",
    "    if type(layer) != Dense:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 9**\n",
    "- Two dense layers with class weights to scale the loss function\n",
    "- Number of epochs = 10\n",
    "- Nothing improvesTotal params: 72,899,752\n",
    "Trainable params: 52,858,984\n",
    "Non-trainable params: 20,040,768\n",
    "_________________________________________________________________\n",
    "Epoch 1/10\n",
    "\n",
    "708/708 [==============================] - 423s - loss: 0.0387 - acc: 0.3163 - val_loss: 5.8928 - val_acc: 0.0223\n",
    "\n",
    "Epoch 2/10\n",
    "\n",
    "708/708 [==============================] - 423s - loss: 0.0162 - acc: 0.6341 - val_loss: 6.0068 - val_acc: 0.0301\n",
    "\n",
    "Epoch 3/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0094 - acc: 0.7735 - val_loss: 6.1302 - val_acc: 0.0258\n",
    "\n",
    "Epoch 4/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0060 - acc: 0.8587 - val_loss: 6.2693 - val_acc: 0.0337\n",
    "\n",
    "Epoch 5/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0040 - acc: 0.9068 - val_loss: 6.6697 - val_acc: 0.0211\n",
    "\n",
    "Epoch 6/10\n",
    "\n",
    "708/708 [==============================] - 418s - loss: 0.0027 - acc: 0.9402 - val_loss: 6.6209 - val_acc: 0.0313\n",
    "\n",
    "Epoch 7/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0019 - acc: 0.9605 - val_loss: 6.8412 - val_acc: 0.0229\n",
    "\n",
    "Epoch 8/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0015 - acc: 0.9699 - val_loss: 7.3279 - val_acc: 0.0207\n",
    "\n",
    "Epoch 9/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0014 - acc: 0.9744 - val_loss: 6.9323 - val_acc: 0.0317\n",
    "\n",
    "Epoch 10/10\n",
    "\n",
    "708/708 [==============================] - 419s - loss: 0.0011 - acc: 0.9785 - val_loss: 7.2606 - val_acc: 0.0270\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "class PseudoLabeling:\n",
    "    def __init__(self, model, train, valid, path = None):\n",
    "        self.model = model\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.path = path\n",
    "        self.val_pred_labels = None\n",
    "        \n",
    "    def predict_labels(self, batch):\n",
    "        pred_probs = self.model.predict_generator(batch, steps = ((batch.samples/batch.batch_size) + 1))\n",
    "        pred_labels = np.zeros_like(pred_probs)\n",
    "        pred_labels[np.arange(len(pred_labels)), pred_probs.argmax(1)] = 1\n",
    "        return pred_labels\n",
    "    \n",
    "    def predict_validation_labels(self):\n",
    "        self.val_pred_labels = self.predict_labels(self.valid)\n",
    "        \n",
    "    def reset_validation_labels(self):\n",
    "        self.val_pred_labels = None\n",
    "        \n",
    "    def get_validation_labels(self, idx_array = None):\n",
    "        if self.val_pred_labels is None:\n",
    "            raise Exception('Validation labels not populated. \\\n",
    "                            Call predict_validation_labels on Pseudolabeling object \\\n",
    "                            to populate validation labels first')\n",
    "        validation_labels = []\n",
    "        if idx_array is None:\n",
    "            return self.val_pred_labels\n",
    "        else:\n",
    "            for idx in idx_array:\n",
    "                validation_labels.append(self.val_pred_labels[idx])\n",
    "                \n",
    "            return validation_labels   \n",
    "\n",
    "    def next(self, *args, **kwargs):\n",
    "        batch_train_x, batch_train_y = next(self.train)\n",
    "        \n",
    "        batch_valid_idx_array, batch_valid_cur_idx, batch_size = next(self.valid.index_generator)\n",
    "        batch_valid_x = np.zeros((batch_size,) + self.valid.image_shape, dtype=K.floatx())\n",
    "        grayscale = self.valid.color_mode == 'grayscale'\n",
    "        \n",
    "        for i, j in enumerate(batch_valid_idx_array):\n",
    "            fname = self.valid.filenames[j]\n",
    "            img = load_img(\n",
    "                  os.path.join(self.valid.directory, fname),\n",
    "                  grayscale=grayscale,\n",
    "                  target_size=self.valid.target_size)\n",
    "            x = img_to_array(img, data_format=self.valid.data_format)\n",
    "            x = self.valid.image_data_generator.random_transform(x)\n",
    "            x = self.valid.image_data_generator.standardize(x)\n",
    "            batch_valid_x[i] = x\n",
    "            \n",
    "        #if self.val_pred_labels is None:\n",
    "        #    batch_valid_y = np.zeros((len(batch_valid_x), self.valid.num_class), dtype=K.floatx())\n",
    "        #    for i, label in enumerate(self.valid.classes[batch_valid_idx_array]):\n",
    "        #        batch_valid_y[i, label] = 1.\n",
    "        #else:\n",
    "        batch_valid_y = self.get_validation_labels(batch_valid_idx_array);\n",
    "        \n",
    "        n0 = np.concatenate([batch_train_x, batch_valid_x])\n",
    "        n1 = np.concatenate([batch_train_y, batch_valid_y])\n",
    "        return (n0, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = gen_batches(path + 'train', batch_size = 32)\n",
    "#valid = gen_batches(path + 'valid', batch_size = 16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 10**\n",
    "- Pseudolabeling of the validation class\n",
    "- Does not improve accuracy at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_steps = train.samples/train.batch_size;\n",
    "#valid_steps = valid.samples/valid.batch_size;\n",
    "\n",
    "#with tf.device('/gpu:0'):\n",
    "#            model.fit_generator(train, steps_per_epoch = train_steps, epochs = 1, \n",
    "#                                validation_data = valid, \n",
    "#                                validation_steps = valid_steps,                 \n",
    "#                               )\n",
    "#            for i in range(4):\n",
    "#                pseudo = PseudoLabeling(model, train, valid, path)\n",
    "#                print (\"Predicting validation labels\")\n",
    "#                pseudo.predict_validation_labels()\n",
    "#                print(\"Done predicting validation labels\")\n",
    "#                model.fit_generator(pseudo, steps_per_epoch = train_steps, epochs = 1,\n",
    "#                                    validation_data = valid,\n",
    "#                                    validation_steps = valid_steps,\n",
    "#                                   )\n",
    "#\n",
    "#            model.save_weights(path + 'weights_exp10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import keras.backend as K\n",
    "data_path = '/work/04381/ymarathe/maverick/yearbook/'\n",
    "\n",
    "class RegressDataGen:\n",
    "    def __init__(self, directory, map_file):\n",
    "        self.directory = directory\n",
    "        self.map_file = map_file\n",
    "        self.filenames = []\n",
    "        self.map = {}\n",
    "        self.populate_filenames()\n",
    "        self.populate_mapping()\n",
    "        self.regressIter = None\n",
    "        self.steps = 0\n",
    "        \n",
    "    def _recursive_list(self, subpath):\n",
    "        return sorted(\n",
    "            os.walk(subpath, followlinks=False), key=lambda tpl: tpl[0])\n",
    "    \n",
    "    def populate_mapping(self):\n",
    "        f = open(self.map_file, 'r')\n",
    "\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            image, year = line.split(\"\\t\")\n",
    "            self.map[image] = year\n",
    "            \n",
    "    def populate_filenames(self):\n",
    "        base_dir = self.directory\n",
    "        for root, _, files in self._recursive_list(base_dir):\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith('.' + 'png'):\n",
    "                    self.filenames.append(os.path.relpath(os.path.join(root, fname), base_dir))\n",
    "                    \n",
    "    def flow_from_directory(self, batch_size = 32, shuffle = True, seed = 42, target_size = (171, 186)):\n",
    "        self.regressIter = Iterator(len(self.filenames), batch_size = batch_size, shuffle = shuffle, seed = seed)\n",
    "        self.steps = math.ceil(len(self.filenames)/batch_size)\n",
    "        return self\n",
    "    \n",
    "    def next(self, *args, **kwargs):\n",
    "        target_size = (171, 186, 3)\n",
    "           \n",
    "        idx_array, cur_idx, bs = next(self.regressIter.index_generator)\n",
    "        \n",
    "        batch_x = np.zeros(tuple([len(idx_array)] + list(target_size)), dtype=K.floatx())\n",
    "        \n",
    "        batch_y = np.zeros(tuple([len(idx_array)]), dtype=K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(idx_array):\n",
    "            fname = self.filenames[j]\n",
    "            img = load_img(\n",
    "                  os.path.join(self.directory, fname),\n",
    "                  grayscale = True,\n",
    "                  target_size= target_size)\n",
    "            x = np.array(img_to_array(img, data_format='channels_last'))\n",
    "            batch_x[i] = x\n",
    "            batch_y[i] = self.map[fname]\n",
    "        \n",
    "        return (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = RegressDataGen(data_path + 'train',\n",
    "                             data_path + 'yearbook_train.txt')\n",
    "valid = RegressDataGen(data_path + 'valid',\n",
    "                             data_path + 'yearbook_valid.txt')\n",
    "\n",
    "train = train.flow_from_directory()\n",
    "valid = valid.flow_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_81 (ZeroPaddi (None, 173, 188, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 171, 186, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_82 (ZeroPaddi (None, 173, 188, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 171, 186, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 85, 93, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_83 (ZeroPaddi (None, 87, 95, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 85, 93, 128)       73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_84 (ZeroPaddi (None, 87, 95, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 85, 93, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 42, 46, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_85 (ZeroPaddi (None, 44, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 42, 46, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_86 (ZeroPaddi (None, 44, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 42, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_87 (ZeroPaddi (None, 44, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 42, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_88 (ZeroPaddi (None, 44, 48, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 42, 46, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 21, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_89 (ZeroPaddi (None, 23, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 21, 23, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_90 (ZeroPaddi (None, 23, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 21, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_91 (ZeroPaddi (None, 23, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 21, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_92 (ZeroPaddi (None, 23, 25, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 21, 23, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 10, 11, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_93 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_94 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_95 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_96 (ZeroPaddi (None, 12, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 10, 11, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 12800)             51200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              52432896  \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 72,528,961\n",
      "Trainable params: 52,436,993\n",
      "Non-trainable params: 20,091,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mean_value = 0\n",
    "for key in freq:\n",
    "    mean_value += freq[key] * float(key)\n",
    "    \n",
    "model = vgg19_conv_layers_sequential()\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, kernel_initializer='glorot_normal', bias_initializer=keras.initializers.Ones()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, activation='relu', bias_initializer=keras.initializers.Constant(mean_value)))\n",
    "\n",
    "for layer in model.layers:\n",
    "    if type(layer) != Dense:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(Adam(lr=1e-2), loss='mse', metrics=['accuracy', 'mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with tf.device('/gpu:0'):\n",
    "           model.fit_generator(train, steps_per_epoch = train.steps, epochs = 1,                                \n",
    "                                validation_data = valid, \n",
    "                                validation_steps = valid.steps, \n",
    "                               )\n",
    "           model.save_weights(path + 'weights_exp11.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 11**\n",
    "- Model as a regression problem\n",
    "- Metrics = accuracy, mae\n",
    "- One dense layer (4096), BatchNorm, second dense layer (1)\n",
    "- No dropout\n",
    "- lr = 1e-3\n",
    "- Slow convergence\n",
    "Epoch 1/1\n",
    "\n",
    "713/713 [==============================] - 429s - loss: 1318.5696 - acc: 4.3829e-05 - mean_absolute_error: 1318.5696 - val_loss: 627.1355 - val_acc: 4.0064e-04 - val_mean_absolute_error: 627.1355\n",
    "\n",
    "- lr = 1e-2\n",
    "\n",
    "Total params: 72,528,961\n",
    "\n",
    "Trainable params: 52,436,993\n",
    "\n",
    "Non-trainable params: 20,091,968\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "713/713 [==============================] - 428s - loss: 348.7608 - acc: 0.0013 - mean_absolute_error: 348.7608 - val_loss: 302.1588 - val_acc: 0.0010 - val_mean_absolute_error: 302.1588\n",
    "\n",
    "- lr = 1e-2\n",
    "- bias_initializer = mean of values\n",
    "\n",
    "Epoch 1/1\n",
    "\n",
    "713/713 [==============================] - 428s - loss: 11.1228 - acc: 0.0319 - mean_absolute_error: 11.1228 - val_loss: 10.2767 - val_acc: 0.0351 - val_mean_absolute_error: 10.2767\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 12**\n",
    "- More number of epochs\n",
    "\n",
    "Total params: 72,528,961\n",
    "\n",
    "Trainable params: 52,436,993\n",
    "\n",
    "Non-trainable params: 20,091,968\n",
    "\n",
    "Epoch 1/4\n",
    "\n",
    "713/713 [==============================] - 428s - loss: 11.1498 - acc: 0.0313 - mean_absolute_error: 11.1498 - val_loss: 9.9395 - val_acc: 0.0453 - val_mean_absolute_error: 9.9395\n",
    "\n",
    "Epoch 2/4\n",
    "\n",
    "713/713 [==============================] - 472s - loss: 9.5142 - acc: 0.0376 - mean_absolute_error: 9.5142 - val_loss: 11.3703 - val_acc: 0.0340 - val_mean_absolute_error: 11.3703\n",
    "\n",
    "Epoch 3/4\n",
    "\n",
    "713/713 [==============================] - 423s - loss: 8.9035 - acc: 0.0401 - mean_absolute_error: 8.9035 - val_loss: 12.3618 - val_acc: 0.0336 - val_mean_absolute_error: 12.3618\n",
    "\n",
    "Epoch 4/4\n",
    "\n",
    "713/713 [==============================] - 423s - loss: 8.5783 - acc: 0.0413 - mean_absolute_error: 8.5783 - val_loss: 12.2621 - val_acc: 0.0323 - val_mean_absolute_error: 12.2621\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "           model.fit_generator(train, steps_per_epoch = train.steps, epochs = 4,                                \n",
    "                                validation_data = valid, \n",
    "                                validation_steps = valid.steps\n",
    "                               )\n",
    "           model.save_weights(path + 'weights_exp12.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
