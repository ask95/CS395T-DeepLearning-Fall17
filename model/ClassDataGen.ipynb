{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Dropout, Flatten, Activation, Lambda, Input\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Lambda\n",
    "from keras import initializers\n",
    "from keras.utils import get_file\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.image import apply_transform, transform_matrix_offset_center\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import random_rotation, random_shear, random_shift, random_zoom\n",
    "from skimage import exposure\n",
    "data_path = '/work/04381/ymarathe/maverick/yearbook/'\n",
    "\n",
    "class ClassDataGen:\n",
    "    def __init__(self, directory, map_file, \n",
    "                 target_size = (171, 186, 3), \n",
    "                 class_weights_train = None, \n",
    "                 multi_output=False, \n",
    "                 do_augmentation=True, \n",
    "                 samplewise_center = True,\n",
    "                 samplewise_std_deviation = True,\n",
    "                 year2idx = None,\n",
    "                 data_aug_factor = 1,\n",
    "                 trainValidSplit = None,\n",
    "                 isTraining = False,\n",
    "                 batch_size = 32,\n",
    "                 shuffle = True,\n",
    "                 seed = 42,\n",
    "                ):\n",
    "        self.directory = directory\n",
    "        self.map_file = map_file\n",
    "        self.filenames = []\n",
    "        self.map = {}\n",
    "        self.fnameToGender = {}\n",
    "        self.target_size = target_size\n",
    "        self.populate_filenames()\n",
    "        self.populate_mapping()\n",
    "        self.regressIter = None\n",
    "        self.steps = 0\n",
    "        self.samplewise_center = samplewise_center\n",
    "        self.samplewise_std_deviation = samplewise_std_deviation\n",
    "        self.height_shift_range = 0.2\n",
    "        self.width_shift_range = 0.2\n",
    "        self.max_rotation = 45\n",
    "        self.shear = 0.785398\n",
    "        self.zoom_range = (0.5, 0.5)\n",
    "        self.do_augmentation = do_augmentation\n",
    "        self.class_weights_train = class_weights_train\n",
    "        self.equalizehist = False\n",
    "        self.multi_output = multi_output\n",
    "        self.lastN = []\n",
    "        self.year2idx = year2idx;\n",
    "        self.batch_size = batch_size;\n",
    "        self.data_aug_factor = data_aug_factor\n",
    "        self.regressIter = Iterator(len(self.filenames), batch_size = self.batch_size, shuffle = shuffle, seed = seed)\n",
    "        self.trainValidSplit = trainValidSplit\n",
    "        self.isTraining = isTraining\n",
    "        self.numTrainingIdx = int(trainValidSplit * len(self.filenames))\n",
    "        self.numValidIdx = len(self.filenames) - self.numTrainingIdx\n",
    "        self.train_test_split()\n",
    "        if self.isTraining:\n",
    "            self.steps = math.ceil(self.numTrainingIdx/batch_size) * self.data_aug_factor\n",
    "        else:\n",
    "            self.steps = math.ceil(self.numValidIdx/batch_size)\n",
    "        \n",
    "    def train_test_split(self):\n",
    "        if self.isTraining:\n",
    "            self.validIdx1 = np.random.randint(0, len(self.filenames))\n",
    "            self.validIdx2 = (self.validIdx1 + self.numValidIdx) % len(self.filenames)\n",
    "        \n",
    "    def getBounds(self):\n",
    "        return (self.validIdx1, self.validIdx2)\n",
    "    \n",
    "    def setBounds(self, validIdx1, validIdx2):\n",
    "        if not self.isTraining:\n",
    "            self.validIdx1 = validIdx1\n",
    "            self.validIdx2 = validIdx2\n",
    "    \n",
    "    def _recursive_list(self, subpath):\n",
    "        return sorted(\n",
    "            os.walk(subpath, followlinks=False), key=lambda tpl: tpl[0])\n",
    "    \n",
    "    def populate_mapping(self):\n",
    "        f = open(self.map_file, 'r')\n",
    "\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            image, year = line.split(\"\\t\")\n",
    "            gender, imfilename = image.split(\"/\")\n",
    "            if gender is 'M':\n",
    "                encodeGender = 1\n",
    "            elif gender is 'F':\n",
    "                encodeGender = 0\n",
    "            self.fnameToGender[image] = encodeGender\n",
    "            self.map[image] = year\n",
    "            \n",
    "    def populate_filenames(self):\n",
    "        base_dir = self.directory\n",
    "        for root, _, files in self._recursive_list(base_dir):\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith('.' + 'png'):\n",
    "                    self.filenames.append(os.path.relpath(os.path.join(root, fname), base_dir))\n",
    "                    \n",
    "    def preprocess(self, x):\n",
    "        if self.equalizehist:\n",
    "            x = exposure.equalize_hist(x)\n",
    "            \n",
    "        return x\n",
    "            \n",
    "    def augment_data(self, x):\n",
    "        \n",
    "        x = random_shift(x, self.width_shift_range, self.height_shift_range, \n",
    "                         row_axis=0, col_axis = 1, channel_axis = 2)\n",
    "        x = random_rotation(x, self.max_rotation, \n",
    "                            row_axis = 0, col_axis = 1, channel_axis = 2)\n",
    "        x = random_shear(x, self.shear, row_axis = 0, col_axis = 1, channel_axis = 2)\n",
    "        x = random_zoom(x, self.zoom_range, row_axis = 0, col_axis = 1, channel_axis = 2)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def oneHotEncodeYear(self, year):\n",
    "        integerEncoded = self.year2idx[year]\n",
    "        oneHotVec = [0 for _ in range(len(self.year2idx))]\n",
    "        oneHotVec[integerEncoded] = 1\n",
    "        return oneHotVec\n",
    "    \n",
    "    def oneHotEncodeGender(self, gender):\n",
    "        oneHotVec = [0, 0]\n",
    "        oneHotVec[gender] = 1;\n",
    "        return oneHotVec\n",
    "    \n",
    "    def modifyIdxArray(self, idx_array):\n",
    "        if self.isTraining:\n",
    "            for i, elem in enumerate(idx_array):\n",
    "                if self.validIdx1 < self.validIdx2:\n",
    "                    if elem >= self.validIdx1 and elem <= self.validIdx2:\n",
    "                        idx_array[i] = np.random.choice([np.random.randint(0, self.validIdx1), \n",
    "                                                 np.random.randint(self.validIdx2, len(self.filenames))])\n",
    "                else:\n",
    "                    if (elem >= self.validIdx1 and elem < len(self.filenames)) or (elem <= self.validIdx2 and elem >= 0):\n",
    "                        idx_array[i] = np.random.choice([np.random.randint(0, self.validIdx2), \n",
    "                                                 np.random.randint(self.validIdx1, len(self.filenames))])\n",
    "                        \n",
    "        else:\n",
    "            for i, elem in enumerate(idx_array):\n",
    "                if elem < self.validIdx1 or elem > self.validIdx2:\n",
    "                    if self.validIdx1 < self.validIdx2:\n",
    "                        idx_array[i] = np.random.randint(self.validIdx1, self.validIdx2)\n",
    "                    else:\n",
    "                        idx_array[i] = np.random.randint(self.validIdx2, self.validIdx1)\n",
    "            \n",
    "        return idx_array\n",
    "                \n",
    "    def next(self, *args, **kwargs):\n",
    "           \n",
    "        self.lastN = []\n",
    "        \n",
    "        idx_array, cur_idx, bs = next(self.regressIter.index_generator)\n",
    "        \n",
    "        if self.trainValidSplit is not None:\n",
    "            self.modifyIdxArray(idx_array)\n",
    "        \n",
    "        batch_x = np.zeros(tuple([len(idx_array)] + list(self.target_size)), dtype=K.floatx())\n",
    "        \n",
    "        batch_y = np.zeros(tuple([len(idx_array)] + list([len(self.year2idx)])), dtype=K.floatx())\n",
    "        \n",
    "        if self.multi_output:\n",
    "            batch_y_gender = np.zeros(tuple([len(idx_array)] + list([2])), dtype=K.floatx())\n",
    "\n",
    "        if self.class_weights_train is not None:\n",
    "            sample_weights = np.ones(tuple([len(idx_array)]), dtype=K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(idx_array):\n",
    "            fname = self.filenames[j]\n",
    "            self.lastN.append(fname)\n",
    "            img = load_img(\n",
    "                  os.path.join(self.directory, fname),\n",
    "                  grayscale = True,\n",
    "                  target_size= self.target_size)\n",
    "            x = np.array(img_to_array(img, data_format='channels_last'))\n",
    "            x = self.preprocess(x)\n",
    "            batch_x[i] = x\n",
    "            batch_y[i, :] = self.oneHotEncodeYear(self.map[fname])\n",
    "            \n",
    "            if self.multi_output:\n",
    "                batch_y_gender[i, :] = self.oneHotEncodeGender(self.fnameToGender[fname])\n",
    "            \n",
    "            if self.class_weights_train is not None:\n",
    "                if self.multi_output:\n",
    "                    sample_weights[i] = self.class_weights_train[self.map[fname]]\n",
    "                else:\n",
    "                    sample_weights[i] = self.class_weights_train[self.map[fname]]\n",
    "        \n",
    "        if self.samplewise_center:\n",
    "            for x in batch_x:\n",
    "                x -= np.mean(x)\n",
    "        \n",
    "        if self.samplewise_std_deviation:\n",
    "            for x in batch_x:\n",
    "                x /= np.std(x)\n",
    "        \n",
    "        if self.do_augmentation:\n",
    "            for x in batch_x:\n",
    "                x = self.augment_data(x)\n",
    "        \n",
    "        if self.multi_output:\n",
    "            if self.class_weights_train is not None:\n",
    "                return batch_x, {'out_year' : batch_y, 'out_gender': batch_y_gender}, {'out_year' : sample_weights, 'out_gender' : sample_weights} \n",
    "            else:\n",
    "                return batch_x, {'out_year' : batch_y, 'out_gender': batch_y_gender}\n",
    "        else:    \n",
    "            if self.class_weights_train is not None:\n",
    "                return (batch_x, batch_y, sample_weights)\n",
    "            else:\n",
    "                return (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
