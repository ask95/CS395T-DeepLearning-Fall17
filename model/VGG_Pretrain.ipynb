{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, BatchNormalization, Dropout, Flatten, Activation, Lambda, Input\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Lambda\n",
    "from keras import initializers\n",
    "from keras.utils import get_file\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "path = '/work/04381/ymarathe/maverick/yearbook/keras_yearbook/'\n",
    "data_path = '/work/04381/ymarathe/maverick/yearbook/'\n",
    "\n",
    "f = open(data_path + 'yearbook_train.txt', 'r')\n",
    "\n",
    "freq = {};\n",
    "normal_const = 0;\n",
    "\n",
    "for line in f:\n",
    "    line = line.rstrip()\n",
    "    image, year = line.split(\"\\t\")\n",
    "    if year in freq:\n",
    "        freq[year] += 1\n",
    "    else:\n",
    "        freq[year] = 1\n",
    "\n",
    "normal_const = np.sum(freq.values())\n",
    "for key in freq:\n",
    "    freq[key] = freq[key]/float(normal_const);\n",
    "    \n",
    "sorted_freq = collections.OrderedDict(sorted(freq.items()))\n",
    "\n",
    "idx = 0;\n",
    "class_weights_train = {}\n",
    "idx2year = {}\n",
    "\n",
    "for key in sorted_freq:\n",
    "    class_weights_train[idx] = sorted_freq[key]\n",
    "    idx2year[idx] = key\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(data_path + 'yearbook_train.txt', 'r')\n",
    "\n",
    "fnameToGenderTr = {}\n",
    "\n",
    "for line in f:\n",
    "    line = line.rstrip()\n",
    "    image, year = line.split(\"\\t\")\n",
    "    gender, imname = image.split(\"/\")\n",
    "    if gender is 'M':\n",
    "        encodeGender = 1\n",
    "    elif gender is 'F':\n",
    "        encodeGender = 0\n",
    "    fnameToGenderTr[image] = encodeGender\n",
    "\n",
    "f = open(data_path + 'yearbook_valid.txt', 'r')\n",
    "\n",
    "fnameToGenderVd = {}\n",
    "\n",
    "for line in f:\n",
    "    line = line.rstrip()\n",
    "    image, year = line.split(\"\\t\")\n",
    "    gender, imname = image.split(\"/\")\n",
    "    if gender is 'M':\n",
    "        encodeGender = 1\n",
    "    elif gender is 'F':\n",
    "        encodeGender = 0\n",
    "    fnameToGenderVd[image] = encodeGender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batches(path, gen = ImageDataGenerator(), shuffle=True, class_mode=\"categorical\", batch_size=32, \n",
    "                target_size=(171, 186)):\n",
    "    return gen.flow_from_directory(path, shuffle=shuffle, batch_size=batch_size, target_size=target_size, \n",
    "                                   class_mode=class_mode)\n",
    "\n",
    "def gen_batches_flow(path, gen = ImageDataGenerator(), shuffle=True, batch_size=32):\n",
    "    return gen.flow(path, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg19_conv_layers_sequential():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(171, 186, 3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    vgg_pretrain_weights = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    \"https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "                                    cache_subdir='models')\n",
    "    \n",
    "    model.load_weights(vgg_pretrain_weights)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def vgg19_full_sequential():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    \n",
    "    vgg_pretrain_weights = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                                    'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                                    cache_subdir='models',\n",
    "                                                    file_hash='cbe5617147190e668d6c5d5026f83318')\n",
    "    \n",
    "    model.load_weights(vgg_pretrain_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg19_conv_functional(img_input):\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "class PseudoLabeling:\n",
    "    def __init__(self, model, train, valid, path = None):\n",
    "        self.model = model\n",
    "        self.train = train\n",
    "        self.valid = valid\n",
    "        self.path = path\n",
    "        self.val_pred_labels = None\n",
    "        \n",
    "    def predict_labels(self, batch):\n",
    "        pred_probs = self.model.predict_generator(batch, steps = ((batch.samples/batch.batch_size) + 1))\n",
    "        pred_labels = np.zeros_like(pred_probs)\n",
    "        pred_labels[np.arange(len(pred_labels)), pred_probs.argmax(1)] = 1\n",
    "        return pred_labels\n",
    "    \n",
    "    def predict_validation_labels(self):\n",
    "        self.val_pred_labels = self.predict_labels(self.valid)\n",
    "        \n",
    "    def reset_validation_labels(self):\n",
    "        self.val_pred_labels = None\n",
    "        \n",
    "    def get_validation_labels(self, idx_array = None):\n",
    "        if self.val_pred_labels is None:\n",
    "            raise Exception('Validation labels not populated. \\\n",
    "                            Call predict_validation_labels on Pseudolabeling object \\\n",
    "                            to populate validation labels first')\n",
    "        validation_labels = []\n",
    "        if idx_array is None:\n",
    "            return self.val_pred_labels\n",
    "        else:\n",
    "            for idx in idx_array:\n",
    "                validation_labels.append(self.val_pred_labels[idx])\n",
    "                \n",
    "            return validation_labels   \n",
    "\n",
    "    def next(self, *args, **kwargs):\n",
    "        batch_train_x, batch_train_y = next(self.train)\n",
    "        \n",
    "        batch_valid_idx_array, batch_valid_cur_idx, batch_size = next(self.valid.index_generator)\n",
    "        batch_valid_x = np.zeros((batch_size,) + self.valid.image_shape, dtype=K.floatx())\n",
    "        grayscale = self.valid.color_mode == 'grayscale'\n",
    "        \n",
    "        for i, j in enumerate(batch_valid_idx_array):\n",
    "            fname = self.valid.filenames[j]\n",
    "            img = load_img(\n",
    "                  os.path.join(self.valid.directory, fname),\n",
    "                  grayscale=grayscale,\n",
    "                  target_size=self.valid.target_size)\n",
    "            x = img_to_array(img, data_format=self.valid.data_format)\n",
    "            x = self.valid.image_data_generator.random_transform(x)\n",
    "            x = self.valid.image_data_generator.standardize(x)\n",
    "            batch_valid_x[i] = x\n",
    "        \n",
    "        batch_valid_y = self.get_validation_labels(batch_valid_idx_array);\n",
    "        \n",
    "        n0 = np.concatenate([batch_train_x, batch_valid_x])\n",
    "        n1 = np.concatenate([batch_train_y, batch_valid_y])\n",
    "        return (n0, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from keras.preprocessing.image import apply_transform, transform_matrix_offset_center\n",
    "import keras.backend as K\n",
    "from skimage import exposure\n",
    "data_path = '/work/04381/ymarathe/maverick/yearbook/'\n",
    "\n",
    "class RegressDataGen:\n",
    "    def __init__(self, directory, map_file, target_size = (171, 186, 3), \n",
    "                 class_weights_train = None, multi_output=False, do_augmentation=True, \n",
    "                 samplewise_center = True,\n",
    "                 samplewise_std_deviation = True):\n",
    "        self.directory = directory\n",
    "        self.map_file = map_file\n",
    "        self.filenames = []\n",
    "        self.map = {}\n",
    "        self.fnameToGender = {}\n",
    "        self.target_size = target_size\n",
    "        self.populate_filenames()\n",
    "        self.populate_mapping()\n",
    "        self.regressIter = None\n",
    "        self.steps = 0\n",
    "        self.samplewise_center = samplewise_center\n",
    "        self.samplewise_std_deviation = samplewise_std_deviation\n",
    "        self.height_shift_range = 0.2\n",
    "        self.width_shift_range = 0.2\n",
    "        self.zoom_range = (0.5, 0.5)\n",
    "        self.do_augmentation = do_augmentation\n",
    "        self.class_weights_train = class_weights_train\n",
    "        self.equalizehist = False\n",
    "        self.multi_output = multi_output\n",
    "        \n",
    "    def _recursive_list(self, subpath):\n",
    "        return sorted(\n",
    "            os.walk(subpath, followlinks=False), key=lambda tpl: tpl[0])\n",
    "    \n",
    "    def populate_mapping(self):\n",
    "        f = open(self.map_file, 'r')\n",
    "\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            image, year = line.split(\"\\t\")\n",
    "            gender, imfilename = image.split(\"/\")\n",
    "            if gender is 'M':\n",
    "                encodeGender = 1\n",
    "            elif gender is 'F':\n",
    "                encodeGender = 0\n",
    "            self.fnameToGender[image] = encodeGender\n",
    "            self.map[image] = year\n",
    "            \n",
    "    def populate_filenames(self):\n",
    "        base_dir = self.directory\n",
    "        for root, _, files in self._recursive_list(base_dir):\n",
    "            for fname in files:\n",
    "                if fname.lower().endswith('.' + 'png'):\n",
    "                    self.filenames.append(os.path.relpath(os.path.join(root, fname), base_dir))\n",
    "                    \n",
    "    def preprocess(self, x):\n",
    "        if self.equalizehist:\n",
    "            x = exposure.equalize_hist(x)\n",
    "            \n",
    "        return x\n",
    "            \n",
    "    def augment_data(self, x):\n",
    "        \n",
    "        if self.height_shift_range:\n",
    "            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * x.shape[0]\n",
    "        else:\n",
    "            tx = 0\n",
    "        \n",
    "        if self.width_shift_range:\n",
    "            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * x.shape[1]\n",
    "        else:\n",
    "            ty = 0\n",
    "        \n",
    "        if tx != 0 or ty != 0:\n",
    "            shift_matrix = np.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])\n",
    "            transform_matrix = shift_matrix\n",
    "            \n",
    "        zx, zy = np.random.uniform(self.zoom_range[0], self.zoom_range[1], 2)\n",
    "        \n",
    "        if zx != 1 or zy != 1:\n",
    "            zoom_matrix = np.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])\n",
    "            transform_matrix = zoom_matrix if transform_matrix is None else np.dot(transform_matrix, zoom_matrix) \n",
    "        \n",
    "        if transform_matrix is not None:\n",
    "            h = self.target_size[0]\n",
    "            w = self.target_size[1]\n",
    "            img_channel_axis = 2\n",
    "            \n",
    "            transform_matrix = transform_matrix_offset_center(transform_matrix, h, w)\n",
    "            \n",
    "            x = apply_transform(\n",
    "                x,\n",
    "                transform_matrix,\n",
    "                img_channel_axis,\n",
    "                fill_mode='nearest',\n",
    "                cval=0)\n",
    "            \n",
    "        return x\n",
    "            \n",
    "    def flow_from_directory(self, batch_size = 32, shuffle = True, seed = 42):\n",
    "        \n",
    "        self.regressIter = Iterator(len(self.filenames), batch_size = batch_size, shuffle = shuffle, seed = seed)\n",
    "        \n",
    "        if self.do_augmentation:\n",
    "            factor = 2\n",
    "        else:\n",
    "            factor = 1\n",
    "        \n",
    "        self.steps = math.ceil(len(self.filenames)/batch_size) * factor\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def next(self, *args, **kwargs):\n",
    "           \n",
    "        idx_array, cur_idx, bs = next(self.regressIter.index_generator)\n",
    "        \n",
    "        batch_x = np.zeros(tuple([len(idx_array)] + list(self.target_size)), dtype=K.floatx())\n",
    "        \n",
    "        if self.multi_output:\n",
    "            batch_y = np.zeros(tuple([len(idx_array)]), dtype=K.floatx())\n",
    "            batch_y_gender = np.zeros(tuple([len(idx_array)]), dtype=K.floatx())\n",
    "            batch_y = np.stack((batch_y, batch_y_gender), axis = -1)\n",
    "        else:\n",
    "            batch_y = np.zeros(tuple([len(idx_array)]), dtype=K.floatx())\n",
    "        \n",
    "        if self.class_weights_train is not None:\n",
    "            sample_weights = np.ones(tuple([len(idx_array)]), dtype=K.floatx())\n",
    "        \n",
    "        for i, j in enumerate(idx_array):\n",
    "            fname = self.filenames[j]\n",
    "            print fname\n",
    "            img = load_img(\n",
    "                  os.path.join(self.directory, fname),\n",
    "                  grayscale = True,\n",
    "                  target_size= self.target_size)\n",
    "            x = np.array(img_to_array(img, data_format='channels_last'))\n",
    "            x = self.preprocess(x)\n",
    "            batch_x[i] = x\n",
    "            if self.multi_output:\n",
    "                batch_y[i, :] = self.map[fname], self.fnameToGender[fname]\n",
    "            else:\n",
    "                batch_y[i] = self.map[fname]\n",
    "            \n",
    "            if self.class_weights_train is not None:\n",
    "                if self.multi_output:\n",
    "                    sample_weights[i] = self.class_weights_train[batch_y[i, 0].astype('int').astype('str')]\n",
    "                else:\n",
    "                    sample_weights[i] = self.class_weights_train[batch_y[i].astype('int').astype('str')]\n",
    "        \n",
    "        if self.samplewise_center:\n",
    "            for x in batch_x:\n",
    "                x -= np.mean(x)\n",
    "        \n",
    "        if self.samplewise_std_deviation:\n",
    "            for x in batch_x:\n",
    "                x /= np.std(x)\n",
    "        \n",
    "        if self.do_augmentation:\n",
    "            for x in batch_x:\n",
    "                x = self.augment_data(x)\n",
    "                \n",
    "        if self.class_weights_train is not None:\n",
    "            return (batch_x, batch_y, sample_weights)\n",
    "        else:\n",
    "            return (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = RegressDataGen(data_path + 'train',\n",
    "                             data_path + 'yearbook_train.txt', class_weights_train = sorted_freq)\n",
    "valid = RegressDataGen(data_path + 'valid',\n",
    "                             data_path + 'yearbook_valid.txt', class_weights_train = sorted_freq)\n",
    "\n",
    "train = train.flow_from_directory()\n",
    "valid = valid.flow_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rounding layer\n",
    "from keras.layers import Layer\n",
    "class Round(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Round, self).__init__(**kwargs)\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        X = self.get_input(train)\n",
    "        return K.round(X)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__}\n",
    "        base_config = super(Round, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import merge\n",
    "\n",
    "mean_value = 0\n",
    "for key in freq:\n",
    "    mean_value += freq[key] * float(key)\n",
    "\n",
    "img_input = Input(shape=(171, 186, 3))\n",
    "x = vgg19_conv_functional(img_input)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(4096, kernel_initializer='glorot_normal', bias_initializer=keras.initializers.Ones())(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x_year = Dense(1, bias_initializer=keras.initializers.Constant(mean_value))(x)\n",
    "out_year = Round()(x_year)\n",
    "x_class = Dense(1, bias_initializer=keras.initializers.Constant(0.5))(x)\n",
    "out_class = Round()(x_class)\n",
    "out = merge((out_year, out_class), 'concat')\n",
    "\n",
    "model = Model([img_input], [out])\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "model.compile(Adam(lr=lr), loss=['mse'], \n",
    "              metrics=['mae'], \n",
    "            )\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "train = RegressDataGen(data_path + 'train',\n",
    "                       data_path + 'yearbook_train.txt', \n",
    "                       class_weights_train = sorted_freq, \n",
    "                       multi_output=True,\n",
    "                       do_augmentation=True\n",
    "                       )\n",
    "valid = RegressDataGen(data_path + 'valid',\n",
    "                       data_path + 'yearbook_valid.txt',\n",
    "                       class_weights_train = sorted_freq,\n",
    "                       do_augmentation=False,\n",
    "                       multi_output=True\n",
    "                      )\n",
    "\n",
    "train = train.flow_from_directory()\n",
    "valid = valid.flow_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ea3f07ed86d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/gpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     model.fit_generator(train, steps_per_epoch = train.steps, epochs = 1,                                \n\u001b[0m\u001b[1;32m      4\u001b[0m                                \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    \n",
    "    model.fit_generator(train, steps_per_epoch = train.steps, epochs = 1,                                \n",
    "                               validation_data = valid, \n",
    "                               validation_steps = valid.steps,\n",
    "                               class_weight=class_weights_train,\n",
    "                               callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                               ModelCheckpoint(path + 'exp28.h5', save_best_only=True)]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "train = RegressDataGen(data_path + 'train',\n",
    "                       data_path + 'yearbook_train.txt', \n",
    "                       class_weights_train = sorted_freq,\n",
    "                       do_augmentation = True)\n",
    "valid = RegressDataGen(data_path + 'valid',\n",
    "                       data_path + 'yearbook_valid.txt',\n",
    "                       class_weights_train = sorted_freq, \n",
    "                       do_augmentation = False)\n",
    "\n",
    "train = train.flow_from_directory()\n",
    "valid = valid.flow_from_directory()\n",
    "\n",
    "mean_value = 0\n",
    "for key in freq:\n",
    "    mean_value += freq[key] * float(key)\n",
    "    \n",
    "model = vgg19_conv_layers_sequential()\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(4096, kernel_initializer='glorot_normal', bias_initializer=keras.initializers.Ones()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, bias_initializer = keras.initializers.Constant(mean_value)))\n",
    "model.add(Round())\n",
    "\n",
    "for layer in model.layers:\n",
    "    if type(layer) != Dense:\n",
    "        layer.trainable = False\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "model.compile(Adam(lr=lr), loss='mse', metrics=['accuracy', 'mae'])\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr * (0.1 ** int(epoch / 10))\n",
    "\n",
    "model.load_weights(path + 'exp27.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F/001510.png\n",
      "M/000603.png\n",
      "M/001875.png\n",
      "F/002578.png\n",
      "M/001851.png\n",
      "M/001562.png\n",
      "F/000176.png\n",
      "F/002276.png\n",
      "M/001531.png\n",
      "F/000397.png\n",
      "M/000399.png\n",
      "M/001685.png\n",
      "F/002640.png\n",
      "M/001101.png\n",
      "F/000292.png\n",
      "F/000089.png\n",
      "F/000600.png\n",
      "F/001944.png\n",
      "M/001121.png\n",
      "F/000438.png\n",
      "F/002722.png\n",
      "M/000944.png\n",
      "F/001951.png\n",
      "F/000138.png\n",
      "M/000043.png\n",
      "F/000997.png\n",
      "F/002092.png\n",
      "F/001882.png\n",
      "F/001028.png\n",
      "M/001014.png\n",
      "M/001349.png\n",
      "F/001746.png\n",
      "[ 1942.72814941] 1936.0 [ 6.72814941]\n",
      "[ 1963.87133789] 1955.0 [ 8.87133789]\n",
      "[ 1986.94189453] 1984.0 [ 2.94189453]\n",
      "[ 1989.73266602] 2005.0 [ 15.26733398]\n",
      "[ 1987.32287598] 1981.0 [ 6.32287598]\n",
      "[ 1981.08483887] 1977.0 [ 4.08483887]\n",
      "[ 1984.91040039] 1984.0 [ 0.91040039]\n",
      "[ 1991.95654297] 1984.0 [ 7.95654297]\n",
      "[ 1956.23022461] 1955.0 [ 1.23022461]\n",
      "[ 1990.31982422] 1992.0 [ 1.68017578]\n",
      "[ 1959.25756836] 1955.0 [ 4.25756836]\n",
      "[ 1953.85705566] 1947.0 [ 6.85705566]\n",
      "[ 1982.25598145] 1979.0 [ 3.25598145]\n",
      "[ 1940.3260498] 1947.0 [ 6.6739502]\n",
      "[ 1935.20947266] 1936.0 [ 0.79052734]\n",
      "[ 1950.09033203] 1933.0 [ 17.09033203]\n",
      "[ 1978.52783203] 1984.0 [ 5.47216797]\n",
      "[ 1967.28417969] 1979.0 [ 11.71582031]\n",
      "[ 1938.95825195] 1940.0 [ 1.04174805]\n",
      "[ 1977.91540527] 1984.0 [ 6.08459473]\n",
      "[ 1962.07226562] 1963.0 [ 0.92773438]\n",
      "[ 1989.73278809] 2001.0 [ 11.26721191]\n",
      "[ 1984.35498047] 1983.0 [ 1.35498047]\n",
      "[ 1978.67993164] 2000.0 [ 21.32006836]\n",
      "[ 1966.7052002] 1965.0 [ 1.7052002]\n",
      "[ 1949.51330566] 1944.0 [ 5.51330566]\n",
      "[ 2003.60083008] 1991.0 [ 12.60083008]\n",
      "[ 2003.14404297] 1992.0 [ 11.14404297]\n",
      "[ 1984.75646973] 1965.0 [ 19.75646973]\n",
      "[ 1988.43029785] 1981.0 [ 7.43029785]\n",
      "[ 1980.03186035] 1984.0 [ 3.96813965]\n",
      "[ 1965.94946289] 1955.0 [ 10.94946289]\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y, sample_weight = next(valid)\n",
    "y_pred = model.predict(batch_x)\n",
    "for i, j in enumerate(y_pred):\n",
    "    print j, batch_y[i], abs(j - batch_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 186, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'F/000176.png'\n",
    "img = load_img(\n",
    "            os.path.join(data_path + 'valid', fname),\n",
    "            grayscale = True,\n",
    "            target_size = (171, 186, 3))\n",
    "x = np.array(img_to_array(img, data_format='channels_last'))\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
